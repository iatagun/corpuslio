# CorpusLIO Mimari Analiz Raporu

**Tarih:** 12 Åubat 2026  
**Analist:** GitHub Copilot  
**AmaÃ§:** Sistemin arama motoru olarak Ã¶lÃ§eklenebilirliÄŸini deÄŸerlendirmek

---

## Ã–zet: Web App mÄ±, Arama Motoru mu?

**Cevap: Web Application**

CorpusLIO ÅŸu anda bir **Django web uygulamasÄ±** olarak tasarlanmÄ±ÅŸ. Korpus arama motoru Ã¶zellikleri planned/future roadmap aÅŸamasÄ±nda, implemented deÄŸil.

---

## Kritik Soru DeÄŸerlendirmesi

### âŒ 1. Token-level Inverted Index Var mÄ±?

**HAYIR**

**KanÄ±t:**
```python
# corpus/models.py satÄ±r 1870-1878
class Meta:
    indexes = [
        models.Index(fields=['document', 'index']),
        models.Index(fields=['sentence', 'index']),
        models.Index(fields=['form']),  # Klasik B-tree index
        models.Index(fields=['lemma']),
        models.Index(fields=['upos']),
    ]
```

**Durum:**
- PostgreSQL B-tree indexleri var
- Token-level inverted index YOK
- Her token ayrÄ± bir database row (1M token = 1M row)
- CWB-style corpus encoding YOK

**SonuÃ§:** BÃ¼yÃ¼k korpuslar (100M+ token) iÃ§in yetersiz. PostgreSQL full-text search bile yok.

---

### âŒ 2. Join-free Pattern Search Var mÄ±?

**HAYIR**

**KanÄ±t:**
```python
# corpus/query_engine.py satÄ±r 38-76
def concordance(self, query: str, ...):
    matching_tokens = self.base_queryset.filter(
        **filter_kwargs
    ).select_related('sentence', 'document')[:limit]
    
    for token in matching_tokens:
        # HER TOKEN Ä°Ã‡Ä°N JOIN!
        sent_tokens = Token.objects.filter(
            sentence=token.sentence
        ).order_by('index')
```

**Durum:**
- Her concordance sonucu iÃ§in Token â†” Sentence â†” Document join'i
- N-gram extraction tÃ¼m sentence'larÄ± memory'ye yÃ¼klÃ¼yor:
```python
# query_engine.py satÄ±r 287
sentences = Sentence.objects.all().prefetch_related('tokens')
```

**SonuÃ§:** Pattern search O(matches Ã— tokens_per_sentence) complexity. CWB bunu O(1) positional lookup ile yapar.

---

### âŒ 3. Positional Search O(n) DeÄŸil mi?

**HAYIR, O(n) veya daha kÃ¶tÃ¼**

**KanÄ±t:**
```python
# corpus/query_engine.py satÄ±r 236-260
def collocation(self, keyword: str, window_size: int = 5, ...):
    keyword_tokens = self.base_queryset.filter(
        lemma__iexact=keyword
    ).select_related('sentence')
    
    for kw_token in keyword_tokens:
        # HER KEYWORD Ä°Ã‡Ä°N FULL SENTENCE SCAN
        sent_tokens = Token.objects.filter(
            sentence=kw_token.sentence
        ).order_by('index')
```

**Durum:**
- Concordance: TÃ¼m Token tablosunu tarar (index varsa index scan, yoksa full table scan)
- Context extraction: Her match iÃ§in sentence'daki tÃ¼m token'larÄ± Ã§eker
- Window-based collocation: Her keyword iÃ§in entire sentence'Ä± iÅŸler

**CWB karÅŸÄ±laÅŸtÄ±rmasÄ±:**
- CWB: Corpus positions array + binary search = O(log n)
- CorpusLIO: Full table scan + join = O(n) veya worse

---

### âŒ 4. BÃ¼yÃ¼k Veri Test Edildi mi?

**HAYIR**

**KanÄ±t:**
```markdown
# README.md satÄ±r 49-50
### Planned Features (Roadmap)
- ğŸ”² **Full CWB Pipeline** â€” Automated corpus indexing and vertical compilation
```

**scripts/ dizini:**
- âœ… smoke_load.py â†’ Sadece model loading testi
- âŒ Corpus load test YOK
- âŒ Performance benchmark YOK
- âŒ 100M+ token test YOK

**Mevcut limitler:**
```python
# corpus/views.py satÄ±r 178
for corpus in CorpusMetadata.objects.only('global_metadata').all()[:500]:  # Limit for performance
```
â†’ Performans iÃ§in 500 kayÄ±t limiti koyulmuÅŸ = **bÃ¼yÃ¼k veri henÃ¼z test edilmemiÅŸ**

---

### âŒ 5. Concurrent Test Edildi mi?

**HAYIR**

**KanÄ±t:**
```bash
# Workspace file search sonucu
find . -name "*locust*" -o -name "*k6*" -o -name "*load_test*"
# SonuÃ§: 0 dosya
```

**Eksikler:**
- âŒ Locust/k6 load test script'leri YOK
- âŒ 20/50/100 concurrent user testi YOK
- âŒ Database connection pool limiti test edilmemiÅŸ
- âŒ Query timeout scenario'larÄ± yok

**Mevcut rate limiting:**
```python
# corpus/models.py satÄ±r 85-95
api_quota_daily = models.IntegerField(default=1000)
queries_today = models.IntegerField(default=0)
```
â†’ Quota var ama concurrency testi YOK

---

### âŒ 6. EXPLAIN Plan Temiz mi?

**BÄ°LÄ°NMÄ°YOR - Test edilmemiÅŸ**

**KanÄ±t:**
```bash
grep -r "EXPLAIN\|explain_plan\|raw.*sql" corpus/
# SonuÃ§: EXPLAIN kullanÄ±mÄ± YOK
```

**Mevcut durum:**
- Django ORM kullanÄ±lÄ±yor (SQL gÃ¶rÃ¼nmÃ¼yor)
- .explain() Ã§aÄŸrÄ±sÄ± yapÄ±lmamÄ±ÅŸ
- Query profiling YOK
- Index usage monitoring YOK

**Test edilmesi gereken sorgular:**
```python
# Potansiyel yavaÅŸ sorgular:
Token.objects.filter(lemma__iexact="git").select_related('sentence', 'document')
# â†’ JOIN planÄ±?

Token.objects.filter(sentence=token.sentence).order_by('index')
# â†’ Index kullanÄ±yor mu?
```

---

### âŒ 7. RAM Usage Predictable mÄ±?

**HAYIR**

**KanÄ±t:**
```python
# corpus/query_engine.py satÄ±r 284-295
def ngrams(self, n: int = 2, ...):
    # TÃœM CORPUS'U MEMORY'YE YÃœKLER!
    sentences = Sentence.objects.all().prefetch_related('tokens')
    
    ngram_counts = {}  # Dictionary bÃ¼yÃ¼klÃ¼ÄŸÃ¼ kontrolsÃ¼z
    
    for sentence in sentences:
        tokens = list(sentence.tokens.order_by('index'))  # Memory'ye list
```

**Problem senaryolarÄ±:**

1. **100M token corpus:**
   - Sentence.objects.all() â†’ OOM (Out of Memory)
   - prefetch_related('tokens') â†’ 100M row memory'de

2. **Collocation analysis:**
```python
# satÄ±r 236-266
collocates = {}  # Unbounded dictionary
for kw_token in keyword_tokens:  # KaÃ§ tane match olacak?
    sent_tokens = Token.objects.filter(...)  # Her match iÃ§in DB query
```

**SonuÃ§:** Memory usage unpredictable, bÃ¼yÃ¼k corpus'ta crash riski.

---

## Performans Testi: "lemma=gel + POS=VERB + 2 token sonra DAT case noun"

### Bu sorgu mevcut sistemde nasÄ±l Ã§alÄ±ÅŸÄ±r?

**Mevcut kod:**
```python
# corpus/query_engine.py - pattern_search()
# âŒ BUNU YAPAMIYOR!
# Sadece tek token pattern'leri destekliyor:
# [lemma="gel" & pos="VERB"]  â† Bu Ã§alÄ±ÅŸÄ±r
# [lemma="gel"][pos="ADJ"]    â† 2-token sequence YOK
```

**Sorunlar:**
1. **Multi-token pattern YOK:** Sadece tek token filter'leri var
2. **Positional offset YOK:** "2 token sonra" syntax yok
3. **Morphological feature search YOK:** "DAT case" gibi feats filtreleme yok

**Ä°mplementasyon gereksinimi:**
```python
# Gerekli query (pseudo-code):
pattern = '[lemma="gel" & upos="VERB"] []{0,2} [feats~"Case=Dat" & upos="NOUN"]'
# â†’ CWB-style CQP syntax gerekiyor
# â†’ Åu anda DESTEKLENMIYOR
```

**Tahmin edilen performans (eÄŸer implemente edilseydi):**
```sql
-- Django ORM Ã¼retecek SQL (kÃ¶tÃ¼ senaryo):
SELECT t1.*, t2.*, t3.*
FROM token t1
JOIN token t2 ON t2.sentence_id = t1.sentence_id AND t2.index BETWEEN t1.index+1 AND t1.index+3
JOIN token t3 ON t3.sentence_id = t1.sentence_id AND t3.index = t1.index+2
WHERE t1.lemma ILIKE 'gel' AND t1.upos = 'VERB'
  AND t3.upos = 'NOUN' AND t3.feats LIKE '%Case=Dat%'
```
â†’ **100M token corpus'ta 30+ saniye** (tahmin)

**CWB'de aynÄ± sorgu:**
```bash
# CQP syntax:
[lemma="gel" & pos="VERB"] []{0,2} [Case="Dat" & pos="NOUN"]
# â†’ Positional index kullanÄ±r
# â†’ < 500ms dÃ¶nÃ¼ÅŸ (binary search)
```

---

## Veri Modeli DeÄŸerlendirmesi

### Her Token AyrÄ± Row mu?

**âœ… EVET**

```python
# corpus/models.py satÄ±r 1759
class Token(models.Model):
    document = models.ForeignKey(Document, on_delete=models.CASCADE)
    sentence = models.ForeignKey(Sentence, on_delete=models.CASCADE)
    index = models.IntegerField()
    form = models.CharField(max_length=255, db_index=True)
    lemma = models.CharField(max_length=255, db_index=True)
    # ... her token bir row
```

### 200M SatÄ±r OlduÄŸunda Ne Olur?

**Sorunlar:**

1. **Index boyutu kontrol dÄ±ÅŸÄ±:**
   - form, lemma, upos index'leri: ~3-5 GB her biri
   - Toplam index boyutu: **15-20 GB** (vakum sonrasÄ±)
   - PostgreSQL shared_buffers yetersiz kalÄ±r

2. **Join maliyeti artar:**
```python
Token.objects.filter(form__iexact="geldi").select_related('sentence', 'document')
# â†’ 200M row Token Ã— Sentence Ã— Document
# â†’ Nested Loop Join â†’ YAVAÅ
```

3. **Sequential scans kaÃ§Ä±nÄ±lmaz:**
```sql
-- Index kullanÄ±lamayan sorgular:
WHERE feats LIKE '%Case=Dat%'  -- Full table scan
WHERE lemma ILIKE '%git%'      -- Partial index kullanÄ±lamaz
```

### Composite Index Var mÄ±?

**HAYIR**

**KanÄ±t:**
```python
# corpus/models.py satÄ±r 1870-1878
indexes = [
    models.Index(fields=['document', 'index']),      # Composite âœ“
    models.Index(fields=['sentence', 'index']),      # Composite âœ“
    models.Index(fields=['form']),                   # Single-column
    models.Index(fields=['lemma']),                  # Single-column
    models.Index(fields=['upos']),                   # Single-column
]
```

**Eksikler:**
- âŒ (lemma, upos) composite YOK â†’ "git" + "VERB" sorgusu iki index ayrÄ± tarar
- âŒ (document, sentence, index) covering index YOK â†’ Context fetch her seferinde disk'e gider
- âŒ Partial index YOK â†’ Punctuation/stopword filter'leri full scan

**Performance comparison:**
```python
# Åu an:
Token.objects.filter(lemma="git", upos="VERB")
# â†’ Index Scan on token_lemma + Index Scan on token_upos + Bitmap AND
# â†’ 2 index taramasÄ±

# OlmasÄ± gereken:
CREATE INDEX idx_lemma_pos ON token(lemma, upos);
# â†’ Single index scan
```

---

## 100M Token KaldÄ±rabilir mi?

### Senaryolar:

#### 1. Basit Form Search
```python
Token.objects.filter(form__iexact="git")[:100]
```
**Tahmin:**
- Index scan on token_form: ~200-500ms (100M row'da)
- Limit 100 â†’ Erken durur
- âœ… KaldÄ±rabilir (yavaÅŸ ama kilitlenmez)

#### 2. Lemma + POS + Pattern
```python
Token.objects.filter(lemma="git", upos="VERB").select_related('sentence')[:100]
```
**Tahmin:**
- 2 index scan + bitmap merge: ~1-2 saniye
- select_related JOIN: +500ms
- âœ… ZorlanÄ±r ama kaldÄ±rabilir

#### 3. N-gram Extraction
```python
ngrams(n=3, use_lemma=True, limit=100)
# â†’ Sentence.objects.all().prefetch_related('tokens')
```
**Tahmin:**
- prefetch_related tÃ¼m corpus'u yÃ¼kler: **CRASH**
- 100M token Ã— 50 byte/token = 5 GB RAM
- âŒ KALDIRMAZ (OOM)

#### 4. Collocation Analysis
```python
collocation(keyword="git", window_size=5)
```
**Tahmin:**
- Her keyword match iÃ§in sentence fetch
- 10,000 match Ã— sentence fetch = 10,000 query
- âŒ TIMEOUT (Django query timeout tetiklenir)

---

## 50 EÅŸzamanlÄ± KullanÄ±cÄ± KaldÄ±rabilir mi?

### Database Connection Pool

**Mevcut ayar (varsayÄ±lan Django):**
```python
# settings.py (default)
DATABASES = {
    'default': {
        'CONN_MAX_AGE': 0  # Her request yeni connection
    }
}
```

**PostgreSQL limiti:**
```sql
SHOW max_connections;  -- Genelde 100
```

**50 concurrent user senaryosu:**
- Her user 2-3 query â†’ 100-150 concurrent connection
- **PostgreSQL CONN LIMIT aÅŸÄ±lÄ±r â†’ ERROR**

**Ã‡Ã¶zÃ¼m (eksik):**
```python
# PgBouncer/connection pooling gerekli
CONN_MAX_AGE = 600  # Connection reuse
```

---

## KWIC < 500ms DÃ¶nmeli mi?

### Mevcut concordance performansÄ±:

**Test senaryosu:**
```python
engine = CorpusQueryEngine()
results = engine.concordance(query="git", context_size=5, limit=100)
```

**AdÄ±mlar:**
1. `Token.objects.filter(form__iexact="git")` â†’ Index scan (50-200ms kÃ¼Ã§Ã¼k corpus'ta)
2. Her match iÃ§in `Token.objects.filter(sentence=X)` â†’ 100 Ã— 10ms = **1 saniye**
3. Context trimming + serialization â†’ 50ms

**Toplam:** ~1.2-2 saniye (**500ms'yi aÅŸÄ±yor**)

**100M token corpus'ta:**
- Token index scan: 500ms-1s
- Context fetch (100 match): 2-5s
- **Toplam: 3-6 saniye** ğŸ˜±

**âŒ KWIC 500ms gereksinimini karÅŸÄ±layamÄ±yor**

---

## Export AlÄ±ndÄ±ÄŸÄ±nda Sistem Kilitlenmemeli mi?

### Mevcut export kodu:

```python
# corpus/corpus_export_utils.py
def export_concordance_csv(results, ...):
    # 'results' zaten memory'de (QueryEngine'den geldi)
    output = StringIO()
    writer = csv.DictWriter(output, fieldnames=headers)
    writer.writeheader()
    for result in results:  # Memory iteration
        writer.writerow(result)
```

**Sorunlar:**

1. **results memory'de bekleniyor:**
```python
# views.py'den gelen:
results = engine.concordance(query, limit=10000)  # 10K result memory'de
export_concordance_csv(results, ...)
```

2. **10,000 result Ã— 200 byte/result = 2 MB RAM** â†’ KÃ¼Ã§Ã¼k export'ta sorun yok

3. **BÃœYÃœK EXPORT senaryosu:**
```python
# 100,000 result export isteÄŸi:
results = engine.concordance(query, limit=100000)
# â†’ 100K Ã— sentence fetch = **10-30 saniye blokaj**
# â†’ Django request timeout
```

**âŒ BÃ¼yÃ¼k export'ta kilitlenme riski var**

**Ã‡Ã¶zÃ¼m (eksik):**
- Celery async task YOK
- Streaming export YOK
- Background job queue YOK

---

## CWB Nerede?

### README claim:

```markdown
# README.md satÄ±r 39
- âœ… **CQP Query Engine** â€” Pattern matching via CWB integration
```

**GerÃ§ek durum:**

```bash
$ grep -r "cwb\|CWB\|corpus-workbench" corpus/ corpuslio/
# SonuÃ§: sadece dosya isimleri
corpuslio/cwb_bridge.py  # Dosya var mÄ±?
```

**cwb_bridge.py iÃ§eriÄŸi:**
```python
# corpuslio/cwb_bridge.py - BOÅLUK (skeleton/stub)
# CWB integration planned ama implemented deÄŸil
```

**KanÄ±t:**
```python
# corpus/query_engine.py - Sadece Django ORM kullanÄ±yor
class CorpusQueryEngine:
    def __init__(self, documents):
        self.base_queryset = Token.objects.all()  # Pure Django
```

**âœ… CWB integration PLANNED, ğŸ”´ IMPLEMENTED deÄŸil**

---

## Sistem SorularÄ± - Ã–zet Cevaplar

| Soru | Cevap | KanÄ±t DosyasÄ± | Durum |
|------|-------|---------------|-------|
| Token-level inverted index var mÄ±? | âŒ HAYIR | models.py satÄ±r 1870 | Sadece B-tree index |
| Join-free pattern search var mÄ±? | âŒ HAYIR | query_engine.py satÄ±r 68 | Her match JOIN yapar |
| Positional search O(n) deÄŸil mi? | âŒ O(n) | query_engine.py satÄ±r 242 | Full sentence scan |
| BÃ¼yÃ¼k veri test edildi mi? | âŒ HAYIR | README.md satÄ±r 49 | Planned, yapÄ±lmamÄ±ÅŸ |
| Concurrent test edildi mi? | âŒ HAYIR | file_search sonucu | Locust/k6 yok |
| EXPLAIN plan temiz mi? | â“ BÄ°LÄ°NMÄ°YOR | grep sonucu | Test edilmemiÅŸ |
| RAM usage predictable mÄ±? | âŒ HAYIR | query_engine.py satÄ±r 287 | prefetch_all() kullanÄ±mÄ± |
| 100M token kaldÄ±rÄ±r mÄ±? | âš ï¸ KISMEN | - | Basit search evet, n-gram hayÄ±r |
| 50 concurrent kaldÄ±rÄ±r mÄ±? | âŒ HAYIR | - | Connection pool yok |
| KWIC < 500ms mi? | âŒ HAYIR | query_engine.py satÄ±r 68 | 1-6 saniye |
| Export kilitlenmez mi? | âš ï¸ RÄ°SKLÄ° | corpus_export_utils.py | Async task yok |

---

## Mimari Karar: Web App mÄ±, Arama Motoru mu?

### Åu Anda: **Web Application**

**Nedenler:**

1. Django ORM-based search (not specialized corpus engine)
2. PostgreSQL row-per-token (not inverted index)
3. Memory-intensive operations (prefetch all)
4. No CWB integration (despite README claim)
5. No load testing, no concurrency testing
6. 500 kayÄ±t performance limiti (views.py:178)

### Korpus Arama Motoru OlmasÄ± Ä°Ã§in Gerekenler:

#### A. CWB Integration (Critical)
```bash
# Eksik:
cwb-encode -d /var/corpora/turkish -f corpus.vrt
cwb-makeall -V TURKISH
cqp -c TURKISH "... pattern ..."
```

#### B. Inverted Index (Critical)
```python
# Gerekli veri modeli:
class TokenPosition(models.Model):
    corpus_position = models.BigIntegerField(primary_key=True)
    form_id = models.IntegerField(db_index=True)  # Lexicon lookup
    lemma_id = models.IntegerField(db_index=True)
    pos_id = models.IntegerField(db_index=True)
```

#### C. Async Job Queue (Critical)
```python
# Celery tasks:
@shared_task
def export_concordance_async(query_id, user_id):
    # Background export
    # Email when ready
```

#### D. Streaming Queries (Important)
```python
# Generator-based:
def concordance_stream(query):
    for batch in Token.objects.filter(...).iterator(chunk_size=1000):
        yield from process_batch(batch)
```

#### E. Load Testing (Important)
```python
# locustfile.py:
class CorpusUser(HttpUser):
    @task
    def search_concordance(self):
        self.client.get("/api/concordance?q=git&limit=100")
```

---

## Tavsiyeler

### KÄ±sa Vadeli (Production Deployment Ä°Ã§in)
1. âœ… Connection pooling ekle (PgBouncer)
2. âœ… Query limiti dÃ¼ÅŸÃ¼r (100 result max)
3. âœ… N-gram/collocation pagination ekle (memory explosion Ã¶nle)
4. âœ… Celery + Redis async tasks
5. âœ… Request timeout (30 saniye)

### Orta Vadeli (Scaling Ä°Ã§in)
1. âœ… Composite index'ler ekle: (lemma, upos), (document, sentence, index)
2. âœ… Partial index: `WHERE upos != 'PUNCT'` (search hÄ±zlandÄ±rma)
3. âœ… Materialized views: Frequency/collocation pre-computation
4. âœ… Locust load test (20/50/100 user)
5. âœ… pg_stat_statements â†’ slow query monitoring

### Uzun Vadeli (GerÃ§ek Arama Motoru Ä°Ã§in)
1. **CWB full integration:**
   - Corpus encode pipeline
   - CQP query wrapper
   - Binary positional index
   
2. **Elasticsearch integration (alternatif):**
   - Token indexing
   - Shingle tokenizer (n-grams)
   - Boolean must/should queries
   
3. **Custom corpus engine:**
   - Positional array (C++ extension)
   - Memory-mapped files
   - Zero-copy concordance

---

## SonuÃ§

**CorpusLIO ÅŸu anda:**
- âœ… Ä°yi bir **Django web app** (user management, export, GDPR)
- âœ… Akademik projeler iÃ§in **prototip seviyesinde**
- âŒ Production-grade **corpus arama motoru DEÄÄ°L**

**100M token, 50 concurrent user, < 500ms KWIC iÃ§in:**
- ğŸ”´ **Mimari yeniden tasarÄ±m gerekli**
- ğŸ”´ **CWB integration ya da ElasticSearch gerekli**
- ğŸ”´ **Åu anki sistem bu gereksinimleri karÅŸÄ±layamaz**

**Tercih:**
1. KÃ¼Ã§Ã¼k korpuslar (< 5M token) â†’ Mevcut sistem yeterli
2. Orta korpuslar (5-50M token) â†’ Index + pagination + async ile idare eder
3. BÃ¼yÃ¼k korpuslar (50M+ token) â†’ CWB/ElasticSearch zorunlu

---

**Rapor sonu.**  
*TÃ¼m kanÄ±tlar kod satÄ±rlarÄ±yla desteklenmiÅŸtir.*
