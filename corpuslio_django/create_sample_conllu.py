"""
Create sample CoNLL-U document for testing Week 4 features.
"""

import os
import sys
import django

# Setup paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)

# Add project root to path
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

# Setup Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'corpuslio_django.settings')
django.setup()

from django.contrib.auth.models import User
from django.core.files.uploadedfile import SimpleUploadedFile
from corpus.models import Document, Analysis
from corpuslio.parsers.conllu_parser import CoNLLUParser

# Sample Turkish CoNLL-U data (3 sentences)
SAMPLE_CONLLU = """# sent_id = 1
# text = TÃ¼rk dili Ã§ok zengindir.
1	TÃ¼rk	TÃ¼rk	PROPN	Prop	Case=Nom|Number=Sing	2	nmod	_	_
2	dili	dil	NOUN	Noun	Case=Nom|Number=Sing|Number[psor]=Sing|Person[psor]=3	4	nsubj	_	_
3	Ã§ok	Ã§ok	ADV	Adverb	_	4	advmod	_	_
4	zengindir	zengin	ADJ	Adj	Aspect=Perf|Mood=Gen|Number=Sing|Person=3|Polarity=Pos|Tense=Pres	0	root	_	SpaceAfter=No
5	.	.	PUNCT	Punc	_	4	punct	_	_

# sent_id = 2
# text = Bu platformu araÅŸtÄ±rmacÄ±lar kullanÄ±yor.
1	Bu	bu	DET	Det	_	2	det	_	_
2	platformu	platform	NOUN	Noun	Case=Acc|Number=Sing	4	obj	_	_
3	araÅŸtÄ±rmacÄ±lar	araÅŸtÄ±rmacÄ±	NOUN	Noun	Case=Nom|Number=Plur	4	nsubj	_	_
4	kullanÄ±yor	kullan	VERB	Verb	Aspect=Prog|Mood=Ind|Number=Plur|Person=3|Polarity=Pos|Tense=Pres	0	root	_	SpaceAfter=No
5	.	.	PUNCT	Punc	_	4	punct	_	_

# sent_id = 3
# text = BaÄŸÄ±mlÄ±lÄ±k analizleri dilbilimde Ã¶nemlidir.
1	BaÄŸÄ±mlÄ±lÄ±k	baÄŸÄ±mlÄ±lÄ±k	NOUN	Noun	Case=Nom|Number=Sing	2	nmod	_	_
2	analizleri	analiz	NOUN	Noun	Case=Nom|Number=Plur|Number[psor]=Sing|Person[psor]=3	4	nsubj	_	_
3	dilbilimde	dilbilim	NOUN	Noun	Case=Loc|Number=Sing	4	obl	_	_
4	Ã¶nemlidir	Ã¶nemli	ADJ	Adj	Aspect=Perf|Mood=Gen|Number=Sing|Person=3|Polarity=Pos|Tense=Pres	0	root	_	SpaceAfter=No
5	.	.	PUNCT	Punc	_	4	punct	_	_

"""

def create_sample_document():
    """Create a document with CoNLL-U dependency annotations."""
    
    print("="*70)
    print("SAMPLE CONLLU DOCUMENT CREATOR")
    print("="*70)
    
    # Get or create admin user
    try:
        user = User.objects.get(username='admin')
        print(f"\nâœ“ Using existing user: {user.username}")
    except User.DoesNotExist:
        user = User.objects.filter(is_superuser=True).first()
        if not user:
            print("\nâŒ No admin user found. Please create one first with:")
            print("   python manage.py createsuperuser")
            return
        print(f"\nâœ“ Using superuser: {user.username}")
    
    # Parse CoNLL-U
    print("\nğŸ“ Parsing sample CoNLL-U data...")
    tokens = CoNLLUParser.parse(SAMPLE_CONLLU)
    print(f"   âœ“ Parsed {len(tokens)} tokens from 3 sentences")
    
    # Create document
    print("\nğŸ“„ Creating document...")
    test_file = SimpleUploadedFile(
        "turkce_bagimlilil_ornegi.txt",
        b"Turk dili cok zengindir. Bu platformu arastirmacilar kullaniyor. Bagimlilik analizleri dilbilimde onemlidir.",
        content_type="text/plain"
    )
    
    document = Document.objects.create(
        filename="turkce_bagimlilil_ornegi.txt",
        file=test_file,
        format="txt",
        author="OCRchestra Team",
        genre="Ã–rnek Metin",
        language="tr",
        processed=True  # Mark as processed
    )
    print(f"   âœ“ Document created: ID={document.id}")
    print(f"   âœ“ Filename: {document.filename}")
    
    # Create analysis with CoNLL-U data
    print("\nğŸ”¬ Creating analysis with dependency annotations...")
    analysis = Analysis.objects.create(
        document=document,
        data={
            'text': 'TÃ¼rk dili Ã§ok zengindir. Bu platformu araÅŸtÄ±rmacÄ±lar kullanÄ±yor. BaÄŸÄ±mlÄ±lÄ±k analizleri dilbilimde Ã¶nemlidir.',
            'word_count': 15,
            'sentences': 3
        },
        conllu_data=tokens,
        has_dependencies=True,
        dependency_parser='stanza-tr-v2.0'
    )
    print(f"   âœ“ Analysis created: ID={analysis.id}")
    print(f"   âœ“ Parser: {analysis.dependency_parser}")
    print(f"   âœ“ Dependency count: {analysis.get_dependency_count()}")
    
    # Display dependency relations
    print("\nğŸ“Š Dependency relations found:")
    relations = analysis.get_dependency_relations()
    for rel, count in sorted(relations.items(), key=lambda x: -x[1])[:10]:
        print(f"   - {rel}: {count}")
    
    print("\n" + "="*70)
    print("âœ… SAMPLE DOCUMENT CREATED SUCCESSFULLY!")
    print("="*70)
    print(f"\nğŸŒ Access the document at:")
    print(f"   http://127.0.0.1:8000/analysis/{document.id}/")
    print(f"\nğŸ” Dependency search:")
    print(f"   http://127.0.0.1:8000/dependency/{document.id}/")
    print(f"\nğŸŒ³ Dependency tree visualization:")
    print(f"   http://127.0.0.1:8000/dependency/{document.id}/tree/1/")
    print(f"\nğŸ“ˆ Dependency statistics:")
    print(f"   http://127.0.0.1:8000/dependency/{document.id}/statistics/")
    print("\n" + "="*70)
    
    return document

if __name__ == '__main__':
    doc = create_sample_document()
